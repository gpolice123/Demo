import tensorflow as tf
import keras
#from tensorflow import keras
from keras.callbacks import TensorBoard, ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
import numpy as np
import matplotlib.pyplot as plt
import imageio
#import pandas as pd
batch_size = 128
num_classes = 10
epochs = 1

with open('C:\\Python27\\machinelearninginaction\\write\\mnist_train.csv') as training_data_file:
    training_data_list = training_data_file.readlines()
with open('C:\\Python27\\machinelearninginaction\\write\\mnist_test.csv') as test_data_file:
    test_data_list = test_data_file.readlines()

print(tf.__version__)

train_data = np.array([x.split(',') for x in training_data_list])
train_images = np.asfarray(train_data[:,1:].reshape(train_data.shape[0],28,28))
train_images_reshape = train_images.reshape(train_images.shape[0], 28, 28,1)
train_labels = train_data[:,0]
train_labels_categorical = keras.utils.to_categorical(train_labels, 10)
test_data = np.array([x.split(',') for x in test_data_list])
test_images = np.asfarray(test_data[:,1:].reshape(test_data.shape[0],28,28))
test_images_reshape = test_images.reshape(test_images.shape[0], 28, 28, 1)
test_labels = test_data[:,0]
test_labels_categorical = keras.utils.to_categorical(test_labels, 10)

train_images_reshape = train_images_reshape / 255.0
test_images_reshape = test_images_reshape / 255.0

# model = keras.Sequential([
#     keras.layers.Conv2D(32, kernel_size=(3, 3),
#                  activation='relu',
#                  input_shape=(28,28,1)),
#     keras.layers.MaxPooling2D(pool_size=(2, 2)),
#     keras.layers.Conv2D(64, (3, 3), activation='relu'),
#     keras.layers.MaxPooling2D(pool_size=(2, 2)),
#     keras.layers.Dropout(0.25),
#     keras.layers.Flatten(),
#     keras.layers.Dense(128, activation='relu'),
#     keras.layers.Dropout(0.5),
#     keras.layers.Dense(10, activation='softmax')
# ])
model = keras.Sequential([
    keras.layers.Conv2D(6, kernel_size=(5, 5), strides=1, padding='same',activation='tanh', input_shape=(28,28,1)),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Dropout(0.25),
    keras.layers.Conv2D(16, kernel_size=(5, 5), strides=1, padding='valid', activation='tanh'),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Dropout(0.25),
    keras.layers.Conv2D(120, kernel_size=(1, 1), strides=1, padding='valid', activation='tanh'),
    keras.layers.Flatten(),
    keras.layers.Dense(84, activation='relu'),
    keras.layers.Dropout(0.25),
    keras.layers.Dense(10, activation='softmax')
])



model.compile(loss=keras.losses.categorical_crossentropy,
              #optimizer=keras.optimizers.Adadelta(),
              optimizer=keras.optimizers.sgd(),
              metrics=['accuracy'])
print(train_images.shape)
print(train_labels.shape)

checkpoint = ModelCheckpoint('./log/ep{epoch:02d}-loss{loss:.4f}-val_acc{val_acc:.4f}.h5',
                             monitor='val_acc', save_weights_only=False, save_best_only=True, period=2)

model.fit(train_images_reshape, train_labels_categorical, epochs=20, validation_split=0.1, callbacks=[checkpoint])

model.save('my_model_LeNet_100loop1.h5')

test_loss, test_acc = model.evaluate(test_images_reshape, test_labels_categorical)
print('Test loss:', test_loss)
print('Test accuracy:', test_acc)

